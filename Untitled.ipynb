{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4b8c017-e4da-474d-9b27-3d087f333677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890718c4-2cbe-4438-844b-d2dc608377da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/result_review.csv', index_col = 'review_idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38625dda-ea2e-4344-88f4-e6054bce8d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cos_name</th>\n",
       "      <th>user_nm</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>원더 세라마이드 모찌 토너</td>\n",
       "      <td>두치봉구</td>\n",
       "      <td>5</td>\n",
       "      <td>완전 가성비 최고 대용량 토너예요! 가격도 엄청 저렴한데 용량이 어마무시해서 스킨팩...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>원더 세라마이드 모찌 토너</td>\n",
       "      <td>리뷰쓰는핑핑이</td>\n",
       "      <td>5</td>\n",
       "      <td>예전에 패드 너어어어무 만족해하며 썼던 기억이 떠올라서 구매해 본 토너입니다!! 아...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>원더 세라마이드 모찌 토너</td>\n",
       "      <td>베리베리피치</td>\n",
       "      <td>5</td>\n",
       "      <td>이것민 바르고 화장한다는데 좋네요. 기존 토너보단 에멀젼 느낌이라 지성분들 이것만 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>원더 세라마이드 모찌 토너</td>\n",
       "      <td>냐람지</td>\n",
       "      <td>5</td>\n",
       "      <td>벌써 n병째 재구매하는, 이제는 없어서는 안 될 필수템  지성인 나에게는 4계절 모...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>원더 세라마이드 모찌 토너</td>\n",
       "      <td>헤헤헷잉</td>\n",
       "      <td>5</td>\n",
       "      <td>열분 이거 가성비 갑입니다 양만 믾은 것도 아니고 제품력도 좋습니다  여러번 챱챱 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6695</th>\n",
       "      <td>순행클렌징폼</td>\n",
       "      <td>코비짱짱</td>\n",
       "      <td>5</td>\n",
       "      <td>선물 받아서 사용했는데 너무 순해요 잘못쓰면 따갑고 트러블도 많이 올라오는데 이제품...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6696</th>\n",
       "      <td>순행클렌징폼</td>\n",
       "      <td>고요한시간</td>\n",
       "      <td>4</td>\n",
       "      <td>순행클렌징 폼 내용물의 색깔은 노란끼가 아주 약하게 있는 투명한 색이에요 거의 투명...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6697</th>\n",
       "      <td>순행클렌징폼</td>\n",
       "      <td>꼬꼬우</td>\n",
       "      <td>4</td>\n",
       "      <td>순하구 촉촉해서 만족스러운 제품입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6698</th>\n",
       "      <td>순행클렌징폼</td>\n",
       "      <td>aangmu__</td>\n",
       "      <td>5</td>\n",
       "      <td>좋아서 2통째 쓰는중이에요 ㅎㅎ 순한게 느껴져서 놀러온 친구들도 맘 편히 쓰더라구요...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6699</th>\n",
       "      <td>순행클렌징폼</td>\n",
       "      <td>졸리면커피</td>\n",
       "      <td>4</td>\n",
       "      <td>주르륵 흐를 정도의 수분감있는 젤타입 클렌징 폼입니다. 양도 넉넉하고 살짝 갈색빛이...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6700 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  cos_name   user_nm  rating  \\\n",
       "review_idx                                     \n",
       "0           원더 세라마이드 모찌 토너      두치봉구       5   \n",
       "1           원더 세라마이드 모찌 토너   리뷰쓰는핑핑이       5   \n",
       "2           원더 세라마이드 모찌 토너    베리베리피치       5   \n",
       "3           원더 세라마이드 모찌 토너       냐람지       5   \n",
       "4           원더 세라마이드 모찌 토너      헤헤헷잉       5   \n",
       "...                    ...       ...     ...   \n",
       "6695                순행클렌징폼      코비짱짱       5   \n",
       "6696                순행클렌징폼     고요한시간       4   \n",
       "6697                순행클렌징폼       꼬꼬우       4   \n",
       "6698                순행클렌징폼  aangmu__       5   \n",
       "6699                순행클렌징폼     졸리면커피       4   \n",
       "\n",
       "                                                       review  \n",
       "review_idx                                                     \n",
       "0           완전 가성비 최고 대용량 토너예요! 가격도 엄청 저렴한데 용량이 어마무시해서 스킨팩...  \n",
       "1           예전에 패드 너어어어무 만족해하며 썼던 기억이 떠올라서 구매해 본 토너입니다!! 아...  \n",
       "2           이것민 바르고 화장한다는데 좋네요. 기존 토너보단 에멀젼 느낌이라 지성분들 이것만 ...  \n",
       "3           벌써 n병째 재구매하는, 이제는 없어서는 안 될 필수템  지성인 나에게는 4계절 모...  \n",
       "4           열분 이거 가성비 갑입니다 양만 믾은 것도 아니고 제품력도 좋습니다  여러번 챱챱 ...  \n",
       "...                                                       ...  \n",
       "6695        선물 받아서 사용했는데 너무 순해요 잘못쓰면 따갑고 트러블도 많이 올라오는데 이제품...  \n",
       "6696        순행클렌징 폼 내용물의 색깔은 노란끼가 아주 약하게 있는 투명한 색이에요 거의 투명...  \n",
       "6697                                   순하구 촉촉해서 만족스러운 제품입니다.   \n",
       "6698        좋아서 2통째 쓰는중이에요 ㅎㅎ 순한게 느껴져서 놀러온 친구들도 맘 편히 쓰더라구요...  \n",
       "6699        주르륵 흐를 정도의 수분감있는 젤타입 클렌징 폼입니다. 양도 넉넉하고 살짝 갈색빛이...  \n",
       "\n",
       "[6700 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c5dee34-5e42-4db6-b350-d33bb02eb614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['원더 세라마이드 모찌 토너', '1025 독도 토너', '서플 프레퍼레이션 페이셜 토너', '오 떼르말',\n",
       "       '캐롯 카로틴 카밍 워터 패드', '로열허니 프로폴리스 인리치 에센스', '프로폴리스 에너지 앰플 미스트',\n",
       "       '더 트루 크림 아쿠아 밤', '블루베리 리밸런싱 스킨', '익스트림 크림', '블랙 스네일 크림',\n",
       "       '데일리 모이스쳐 테라피 페이셜 크림', '더 트루 크림 모이스춰라이징 밤', '순정 약산성 5.5 진정 토너',\n",
       "       '다이브인 저분자 히알루론산 세럼', '파워 10 포뮬라 엘아이 이펙터 감초줄렌', '하또무기 스킨 컨디셔너',\n",
       "       '웰빙 녹차 스킨', '윌 프로디쥬스 멀티 드라이 오일', '비폴렌 리뉴 앰풀러', '노세범 미네랄 파우더',\n",
       "       '더블 웨어 스테이 인 플레이스 메이크업 [SPF10/PA++]',\n",
       "       '잉크래스팅 파운데이션 슬림핏 이엑스 [SPF30/PA++]', '핏미 컨실러',\n",
       "       '에센셜 스킨 누더 쿠션 [SPF50+/PA+++]', '래디언트 크리미 컨실러', '더 포어페셔널',\n",
       "       '퓨처리스트 아쿠아 브릴리언스 파운데이션 [SPF20/PA+++]', '디파이닝 커버 컨실러',\n",
       "       '블랙 쿠션 [SPF34/PA++]', '에어 코튼 메이크업 베이스 [SPF30/PA++]',\n",
       "       '래스팅 실크 UV 파운데이션 [SPF20]', '피치뽀송 멀티 피니시 파우더',\n",
       "       '퍼펙팅 래스트 파운데이션 [SPF30/PA++]', 'UHD 프레스드 파우더', '기름종이 파우더',\n",
       "       '올데이 타이트 메이크업 세팅 픽서', '올 나이터 메이크업 세팅 스프레이', '제로 쿠션 [SPF20/PA++]',\n",
       "       '라스트 벨벳 틴트', '레트로 매트 립스틱', '루쥬 쀠르 꾸뛰르 베르니 아 레브르', '차차틴트',\n",
       "       '모이스처라이징 립밤 클래식', '아토덤 립스틱', '스틱레브르 오리지널', '체크 글로시 블라스터 틴트',\n",
       "       '모이스처라이징 립밤 클래식 튜브', '립밤', '쥬시 래스팅 틴트', '딜라이트 토니틴트',\n",
       "       '진저 슈가 오버나이트 립 마스크', '무드 라이어 벨벳 틴트', '루쥬 볼륍떼 샤인', '벨벳 립 틴트',\n",
       "       '디어 달링 워터젤 틴트', '립테라피 오리지널', '따뚜아쥬 꾸뛰르', '룩 앳 마이 아이즈 [카페]',\n",
       "       '히로인메이크 롱앤컬 마스카라 EX', '히로인메이크 스무스 리퀴드 아이라이너 N', '룩 앳 마이 아이즈',\n",
       "       '하드 포뮬라', '매트 아이 컬러', '킬래쉬 수퍼프루프 마스카라 [롱 컬링]', '헤비로테이션 컬러링 아이브로우',\n",
       "       '잉크 블랙 카라 AD [롱래시 컬링]', '매그니피센트 메탈 글리터 & 글로우 리퀴드 아이섀도우',\n",
       "       '섀이드 앤 섀도우', '아이돌 리얼 래쉬 픽서', '스키니 꼼꼼카라', '백젤 아이라이너', '모노 아이즈 [매트]',\n",
       "       '아이섀도우', '닥터마스카라 픽서 포 슈퍼 롱래쉬', '아트클래스 바이 로댕 쉐딩', '치크 팝', '파스텔 블러셔',\n",
       "       '블러쉬', '크리스탈 블러셔', '라스트 블러쉬 [쉐딩]', '러블리 쿠키 블러셔', '내츄럴 치크N',\n",
       "       '샘물 싱글 블러셔', '무드 레시피 페이스 블러쉬', '코튼 블러셔', '코튼 컨투어', '프리즘 하이라이터',\n",
       "       '미네랄라이즈 스킨피니쉬', '그림자 쉐딩', '슈가볼 벨벳 블러셔', '글로우 플로어 치크', '미네랄라이즈 블러쉬',\n",
       "       '매트 래디언스 베이크드 파우더 하이라이터', '샘물 스마일 베베 블러셔', '고급 파우더 브러시 (대)',\n",
       "       '아이래쉬 컬러', '블렌딩 퍼프', '우루우루 화장솜', '핑크팝 브러시', '잘 스며드는 화장솜', '물방울퍼프',\n",
       "       '소프트 아이래쉬 컬', '블러쉬 브러쉬', '소프트 5겹 화장솜', '에어쿠션® 전용 퍼프', 'EBR 눈썹칼',\n",
       "       '미라클 컴플렉션 스펀지', '스키니 픽스 블렌더', '퍼펙트 아이래쉬 컬러', '파우더 오일크리어 페이퍼',\n",
       "       '실속형비후라', '텐션 팩트 퍼프 [밀착]', '블렌딩총알브러시', '힐링 티 가든 그린티 클렌징 워터',\n",
       "       '녹차 필링젤', '힐링 티 가든 티트리 클렌징 워터', '미네랄 립앤아이 메이크업 리무버', '센시비오 H2O',\n",
       "       '퓨어 클렌징 오일', '페이셜 마일드 필링', '클린 잇 제로 클렌징 밤 오리지널',\n",
       "       '클리어 훼이스 스파 립앤아이 메이크업 리무버', '셀 리뉴 바이오 마이크로 필 소프트 젤',\n",
       "       '올리브 리얼 클렌징 티슈', '센시티브 패드', '티스 딥 오프 클렌징 오일', '브라이트닝 필링 젤',\n",
       "       '순행클렌징오일', '스웨덴 에그팩 라놀린 앤 로즈워터', '세이프 미 릴리프 모이스처 클렌징 폼',\n",
       "       '프레쉬 모이스춰 립앤아이 리무버', '살구씨 코 블랙헤드 클렌징 오일', '순행클렌징폼'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cos_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77e734d7-ed9b-4b91-a806-0ac4947c0d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "385b0ce1-0e69-4a64-ba41-e03e372b97f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc4ac5aa-026a-4a11-96da-ec679bbff164",
   "metadata": {},
   "outputs": [],
   "source": [
    "kkma = Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b8e0d95-975e-4738-a8b7-9697d4717ca8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EC': '연결 어미',\n",
       " 'ECD': '의존적 연결 어미',\n",
       " 'ECE': '대등 연결 어미',\n",
       " 'ECS': '보조적 연결 어미',\n",
       " 'EF': '종결 어미',\n",
       " 'EFA': '청유형 종결 어미',\n",
       " 'EFI': '감탄형 종결 어미',\n",
       " 'EFN': '평서형 종결 어미',\n",
       " 'EFO': '명령형 종결 어미',\n",
       " 'EFQ': '의문형 종결 어미',\n",
       " 'EFR': '존칭형 종결 어미',\n",
       " 'EP': '선어말 어미',\n",
       " 'EPH': '존칭 선어말 어미',\n",
       " 'EPP': '공손 선어말 어미',\n",
       " 'EPT': '시제 선어말 어미',\n",
       " 'ET': '전성 어미',\n",
       " 'ETD': '관형형 전성 어미',\n",
       " 'ETN': '명사형 전성 어미',\n",
       " 'IC': '감탄사',\n",
       " 'JC': '접속 조사',\n",
       " 'JK': '조사',\n",
       " 'JKC': '보격 조사',\n",
       " 'JKG': '관형격 조사',\n",
       " 'JKI': '호격 조사',\n",
       " 'JKM': '부사격 조사',\n",
       " 'JKO': '목적격 조사',\n",
       " 'JKQ': '인용격 조사',\n",
       " 'JKS': '주격 조사',\n",
       " 'JX': '보조사',\n",
       " 'MA': '부사',\n",
       " 'MAC': '접속 부사',\n",
       " 'MAG': '일반 부사',\n",
       " 'MD': '관형사',\n",
       " 'MDN': '수 관형사',\n",
       " 'MDT': '일반 관형사',\n",
       " 'NN': '명사',\n",
       " 'NNB': '일반 의존 명사',\n",
       " 'NNG': '보통명사',\n",
       " 'NNM': '단위 의존 명사',\n",
       " 'NNP': '고유명사',\n",
       " 'NP': '대명사',\n",
       " 'NR': '수사',\n",
       " 'OH': '한자',\n",
       " 'OL': '외국어',\n",
       " 'ON': '숫자',\n",
       " 'SE': '줄임표',\n",
       " 'SF': '마침표, 물음표, 느낌표',\n",
       " 'SO': '붙임표(물결,숨김,빠짐)',\n",
       " 'SP': '쉼표,가운뎃점,콜론,빗금',\n",
       " 'SS': '따옴표,괄호표,줄표',\n",
       " 'SW': '기타기호 (논리수학기호,화폐기호)',\n",
       " 'UN': '명사추정범주',\n",
       " 'VA': '형용사',\n",
       " 'VC': '지정사',\n",
       " 'VCN': \"부정 지정사, 형용사 '아니다'\",\n",
       " 'VCP': \"긍정 지정사, 서술격 조사 '이다'\",\n",
       " 'VV': '동사',\n",
       " 'VX': '보조 용언',\n",
       " 'VXA': '보조 형용사',\n",
       " 'VXV': '보조 동사',\n",
       " 'XP': '접두사',\n",
       " 'XPN': '체언 접두사',\n",
       " 'XPV': '용언 접두사',\n",
       " 'XR': '어근',\n",
       " 'XSA': '형용사 파생 접미사',\n",
       " 'XSN': '명사파생 접미사',\n",
       " 'XSV': '동사 파생 접미사'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkma.tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7cafffb-cec3-44ef-b103-9f32f337ea52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'완전 가성비 최고 대용량 토너예요! 가격도 엄청 저렴한데 용량이 어마무시해서 스킨팩으로 아낌없이 쓰기에 너무 좋아요 성분도 크게 나쁜건 없는 것 같고 모찌 토너 이름답게 워터제형이지만 아주 수분감이 없지는 않고 촉촉한 편이예요 좀 가격대 있는 워터토너들은 스킨팩으로 막 쓰기엔 아까웠는데 이 제품은 가격이 너무 훌륭해서 신경쓰지 않고 막 써도 좋아요 '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68a1f283-5f14-4549-9bba-a4e99b555bfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('완전', 'NNG'),\n",
       " ('가', 'VV'),\n",
       " ('아', 'ECS'),\n",
       " ('성비', 'NNG'),\n",
       " ('최고', 'NNG'),\n",
       " ('대용량', 'NNG'),\n",
       " ('토너', 'NNG'),\n",
       " ('이', 'VCP'),\n",
       " ('에요', 'EFN'),\n",
       " ('!', 'SF'),\n",
       " ('가격', 'NNG'),\n",
       " ('도', 'JX'),\n",
       " ('엄청', 'MAG'),\n",
       " ('저렴', 'XR'),\n",
       " ('하', 'XSA'),\n",
       " ('ㄴ', 'ETD'),\n",
       " ('데', 'NNB'),\n",
       " ('용량', 'NNG'),\n",
       " ('이', 'JKS'),\n",
       " ('어', 'VV'),\n",
       " ('어', 'ECS'),\n",
       " ('마무', 'NNG'),\n",
       " ('시해', 'NNG'),\n",
       " ('서', 'JKM'),\n",
       " ('스킨', 'NNG'),\n",
       " ('팩', 'NNG'),\n",
       " ('으로', 'JKM'),\n",
       " ('아낌없이', 'MAG'),\n",
       " ('쓰', 'VV'),\n",
       " ('기에', 'ECD'),\n",
       " ('너무', 'MAG'),\n",
       " ('좋', 'VA'),\n",
       " ('아요', 'EFN'),\n",
       " ('성분', 'NNG'),\n",
       " ('도', 'JX'),\n",
       " ('크', 'VA'),\n",
       " ('게', 'ECD'),\n",
       " ('나쁘', 'VA'),\n",
       " ('ㄴ', 'ETD'),\n",
       " ('건', 'NNM'),\n",
       " ('없', 'VA'),\n",
       " ('는', 'ETD'),\n",
       " ('것', 'NNB'),\n",
       " ('같', 'VA'),\n",
       " ('고', 'ECE'),\n",
       " ('모', 'NNG'),\n",
       " ('찌', 'NNG'),\n",
       " ('토너', 'NNG'),\n",
       " ('이름', 'NNG'),\n",
       " ('답', 'XSA'),\n",
       " ('게', 'ECD'),\n",
       " ('워터', 'NNG'),\n",
       " ('제형', 'NNG'),\n",
       " ('이', 'VCP'),\n",
       " ('지만', 'ECE'),\n",
       " ('아주', 'MAG'),\n",
       " ('수분', 'NNG'),\n",
       " ('감이', 'NNG'),\n",
       " ('없', 'VA'),\n",
       " ('지', 'ECD'),\n",
       " ('는', 'JX'),\n",
       " ('않', 'VXV'),\n",
       " ('고', 'ECE'),\n",
       " ('촉촉', 'XR'),\n",
       " ('하', 'XSA'),\n",
       " ('ㄴ', 'ETD'),\n",
       " ('편', 'NNB'),\n",
       " ('이', 'VCP'),\n",
       " ('에요', 'EFN'),\n",
       " ('좀', 'MAG'),\n",
       " ('가격대', 'NNG'),\n",
       " ('있', 'VV'),\n",
       " ('는', 'ETD'),\n",
       " ('워터', 'NNG'),\n",
       " ('토너', 'NNG'),\n",
       " ('들', 'XSN'),\n",
       " ('은', 'JX'),\n",
       " ('스킨', 'NNG'),\n",
       " ('팩', 'NNG'),\n",
       " ('으로', 'JKM'),\n",
       " ('막', 'MAG'),\n",
       " ('쓰기', 'NNG'),\n",
       " ('에', 'JKM'),\n",
       " ('는', 'JX'),\n",
       " ('아깝', 'VA'),\n",
       " ('었', 'EPT'),\n",
       " ('는데', 'ECD'),\n",
       " ('이', 'MDT'),\n",
       " ('제품', 'NNG'),\n",
       " ('은', 'JX'),\n",
       " ('가격', 'NNG'),\n",
       " ('이', 'JKS'),\n",
       " ('너무', 'MAG'),\n",
       " ('훌륭', 'XR'),\n",
       " ('하', 'XSA'),\n",
       " ('어서', 'ECD'),\n",
       " ('신경', 'NNG'),\n",
       " ('쓰', 'VV'),\n",
       " ('지', 'ECD'),\n",
       " ('않', 'VXV'),\n",
       " ('고', 'ECE'),\n",
       " ('막', 'MAG'),\n",
       " ('쓰', 'VV'),\n",
       " ('어도', 'ECD'),\n",
       " ('좋', 'VA'),\n",
       " ('아요', 'EFN')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkma.pos(data['review'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cc2a2c8-3841-4e34-b6d9-d2531bde82c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myTokenizer(text) :\n",
    "    # 불러온 문장을 인코딩 작업 utf-8 > euc-kr\n",
    "\n",
    "    # 디코딩\n",
    "    \n",
    "    d = pd.DataFrame(kkma.pos(text), columns = ['형태소', '품사'])\n",
    "    d.set_index('품사', inplace = True)\n",
    "    if ('VV' in d.index) | ('VA' in d.index) | ('NNG' in d.index) :\n",
    "        return d.loc[d.index.intersection(['VV','VA','NNG']),'형태소'].values\n",
    "    else :\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11abd50c-df26-4f50-a44c-085254689511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xed in position 0: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m test_token \u001b[38;5;241m=\u001b[39m TfidfVectorizer(tokenizer\u001b[38;5;241m=\u001b[39mmyTokenizer)\n\u001b[1;32m----> 2\u001b[0m test_token\u001b[38;5;241m.\u001b[39mfit(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m test_token\u001b[38;5;241m.\u001b[39mvocabulary_\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2103\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2096\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_for_unused_params()\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2098\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2099\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2100\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2101\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2102\u001b[0m )\n\u001b[1;32m-> 2103\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_transform(raw_documents)\n\u001b[0;32m   2104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1388\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1380\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1381\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1385\u001b[0m             )\n\u001b[0;32m   1386\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count_vocab(raw_documents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_)\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1391\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1275\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1274\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1275\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m analyze(doc):\n\u001b[0;32m   1276\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1277\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:113\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    111\u001b[0m     doc \u001b[38;5;241m=\u001b[39m preprocessor(doc)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     doc \u001b[38;5;241m=\u001b[39m tokenizer(doc)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ngrams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_words \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m, in \u001b[0;36mmyTokenizer\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmyTokenizer\u001b[39m(text) :\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# 불러온 문장을 인코딩 작업 utf-8 > euc-kr\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# 디코딩\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     d \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(kkma\u001b[38;5;241m.\u001b[39mpos(text), columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m형태소\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m품사\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      7\u001b[0m     d\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m품사\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVV\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m d\u001b[38;5;241m.\u001b[39mindex) \u001b[38;5;241m|\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVA\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m d\u001b[38;5;241m.\u001b[39mindex) \u001b[38;5;241m|\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNNG\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m d\u001b[38;5;241m.\u001b[39mindex) :\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\konlpy\\tag\\_kkma.py:81\u001b[0m, in \u001b[0;36mKkma.pos\u001b[1;34m(self, phrase, flatten, join)\u001b[0m\n\u001b[0;32m     79\u001b[0m             morphemes\u001b[38;5;241m.\u001b[39mappend(morpheme\u001b[38;5;241m.\u001b[39mgetString() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m morpheme\u001b[38;5;241m.\u001b[39mgetTag())\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m             morphemes\u001b[38;5;241m.\u001b[39mappend((morpheme\u001b[38;5;241m.\u001b[39mgetString(), morpheme\u001b[38;5;241m.\u001b[39mgetTag()))\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m join:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xed in position 0: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "test_token = TfidfVectorizer(tokenizer=myTokenizer)\n",
    "test_token.fit(data['review'])\n",
    "test_token.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a66c92d-8c52-4010-8897-84aaef5f9378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e319d92-2f94-4fa4-b127-6dc3815206d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb1e787-98b0-4a37-a785-7734c2603953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87a1e99-c3a2-4f2b-8dba-e1b73b389dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd526d-da22-4f53-af40-cfa930fe3e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
