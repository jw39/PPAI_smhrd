{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d271ba-d79e-450a-bed4-83b168b63a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./data/review_before.csv')\n",
    "data.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "data.columns = ['제품명', '닉네임', '나이', '피부타입', '성별', '평점','리뷰내용']\n",
    "data\n",
    "\n",
    "# 평점 기준\n",
    "# 긍정 : 5, 4\n",
    "# 중립 : 3\n",
    "# 부정 : 2, 1\n",
    "\n",
    "data['평점']\n",
    "\n",
    "def rating_replace(rating) :\n",
    "  if rating == 5 or rating == 4 : # 긍정은 2로 변경\n",
    "    return 2\n",
    "  elif rating == 3 : # 중립은 1으로 변경\n",
    "    return 1\n",
    "  else : # 부정은 0로 변경\n",
    "    return 0\n",
    "\n",
    "data['감성분석 결과'] = data['평점'].apply(rating_replace)\n",
    "\n",
    "# 리뷰 내용 전처리\n",
    "X = data['리뷰내용']\n",
    "y = data['감성분석 결과']\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "okt.tagset\n",
    "\n",
    "list_ = []\n",
    "\n",
    "for i in X:\n",
    "  list_.append(okt.pos(i, join=True))\n",
    "\n",
    "list_\n",
    "\n",
    "\n",
    "tagging = []\n",
    "morph = []\n",
    "tag = []\n",
    "\n",
    "for j in range(len(list_)):\n",
    "  for i in list_[j] :\n",
    "    morph.append(i.split('/')[0])\n",
    "    tag.append(i.split('/')[1])\n",
    "  tagging.append([morph, tag])\n",
    "\n",
    "pd.DataFrame(tagging, columns =['morph', 'tag'])\n",
    "\n",
    "def myTokenizer(text):\n",
    "    d = pd.DataFrame(okt.pos(text), columns=['morph','tag'])\n",
    "    d.set_index('tag', inplace=True)\n",
    "    if ('Verb' in d.index) | ('Noun' in d.index) | ('Adjective' in d.index):\n",
    "        return d.loc[d.index.intersection(['Verb','Noun','Adjective']),'morph'].values\n",
    "    else :\n",
    "        return []\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#TF-IDF Vectorizer에 연결해주기\n",
    "tfidf_pos = TfidfVectorizer(tokenizer=myTokenizer)\n",
    "tfidf_pos.fit(X)\n",
    "tfidf_pos.vocabulary_\n",
    "\n",
    "len(tfidf_pos.vocabulary_)\n",
    "\n",
    "# 실제 문장에 단어를 토큰값으로 변환해주는 작업 진행 : 8분정도 걸림\n",
    "X_trains = tfidf_pos.transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trains, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e481dc-cddd-4511-898d-df5b7634fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier() # 하이퍼 파라미터 조절 X / 기본 모델\n",
    "\n",
    "# 교차검증 - 예상 성능 확인해보기\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rs = cross_val_score(rf_model, X_train, y_train, cv = 5)\n",
    "print(rs)\n",
    "print(rs.mean())\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_model.score(X_train, y_train)\n",
    "rf_model.score(X_test, y_test)\n",
    "\n",
    "# 하이퍼 파라미터 조합찾기\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 하이퍼 파라미터 조절\n",
    "# 내가 하이퍼 파라미터 뭉텡이를 던져주면 조합식을 짜서 최적의 조합을 짜줌\n",
    "# 이때 사용하는건 교차검증 점수\n",
    "param = { 'n_estimators' : [500, 1000, 1500, 2000, 2500], # 트리의 갯수 갯수가 많을수록 시간이 오래걸림\n",
    "          'max_depth': range(1,6), # 트리의 최대 깊이 최대 깊이는 5를 안넘는게 좋음...\n",
    "          #'min_samples_split': range(1,6),\n",
    "          #'min_samples_leaf' : range(1,6)\n",
    "\n",
    "        }\n",
    "\n",
    "# range(100, 5001, 100) - 100부터 5000까지 100씩 증가 시켜주세요\n",
    "grid_model = GridSearchCV(rf_model, param, n_jobs=-1, cv = 5)\n",
    "\n",
    "grid_model.fit(X_train, y_train) #시간 좀 걸림\n",
    "\n",
    "print(f\" 최적 교차검증 점수 : {grid_model.best_score_}\") # 최적 파라미터로 찾은 교차검증 점수\n",
    "print(f\" 최적 교차검증 파라미터 목록 : {grid_model.best_params_}\") # 최적 파라미터 목록\n",
    "\n",
    "best_model = grid_model.best_estimator_ # 최적 모델 만들기\n",
    "\n",
    "best_model.fit(X_train, y_train) # 최적 모델 학습\n",
    "best_model.score(X_test, y_test) # 최적 모델 평가 점수\n",
    "\n",
    "# rf 활용\n",
    "# predict_proba : 각 클래스별 불확실성 확률 -> 예측확률을 정답별로 표시\n",
    "# target_names = ['부정', '중립' ,'긍정']\n",
    "target_names = np.array([\"부정\", \"중립\", \"긍정\"])\n",
    "review = ['이 화장품은 촉촉해서 건성 피부를 가지신 분이라면 좋을것 같아요']\n",
    "vect_review = tfidf_pos.transform(review) # 토큰화 변환 진행 코드\n",
    "pre = rf_model.predict(vect_review)\n",
    "print(f\"{review[0]} 문장은 {rf_model.predict_proba(vect_review).max()*100:.2f}%로 {target_names[pre[0]]} 리뷰입니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12bfe9aa-9515-46f1-b639-8a4ae36c3b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰 분석 결과를 'review_predictions.csv'로 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 데이터 로드\n",
    "data = pd.read_csv('./data/review_before.csv')\n",
    "data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "data.columns = ['제품명', '닉네임', '나이', '피부타입', '성별', '평점', '리뷰내용']\n",
    "\n",
    "# 평점 기준\n",
    "def rating_replace(rating):\n",
    "    if rating in [5, 4]:  # 긍정은 2로 변경\n",
    "        return 2\n",
    "    elif rating == 3:  # 중립은 1로 변경\n",
    "        return 1\n",
    "    else:  # 부정은 0으로 변경\n",
    "        return 0\n",
    "\n",
    "data['감성분석 결과'] = data['평점'].apply(rating_replace)\n",
    "\n",
    "# 리뷰 내용 및 감성분석 결과\n",
    "X = data['리뷰내용']\n",
    "y = data['감성분석 결과']\n",
    "\n",
    "# 토큰화 함수 정의\n",
    "okt = Okt()\n",
    "\n",
    "def myTokenizer(text):\n",
    "    d = pd.DataFrame(okt.pos(text), columns=['morph', 'tag'])\n",
    "    d.set_index('tag', inplace=True)\n",
    "    if 'Verb' in d.index or 'Noun' in d.index or 'Adjective' in d.index:\n",
    "        return d.loc[d.index.intersection(['Verb', 'Noun', 'Adjective']), 'morph'].values\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf_pos = TfidfVectorizer(tokenizer=myTokenizer)\n",
    "tfidf_pos.fit(X)\n",
    "\n",
    "# 리뷰 내용 벡터화\n",
    "X_trains = tfidf_pos.transform(X)\n",
    "\n",
    "# 모델 로드 및 학습\n",
    "# 실제로는 학습된 모델을 로드해야 합니다. 여기서는 기본 모델을 사용합니다.\n",
    "rf_model = RandomForestClassifier()  # 하이퍼파라미터 조정된 모델로 교체 필요\n",
    "rf_model.fit(X_trains, y)\n",
    "\n",
    "# 예측 수행\n",
    "probs = rf_model.predict_proba(X_trains)\n",
    "\n",
    "# 최대 확률 및 예측 클래스 계산\n",
    "max_probs = probs.max(axis=1) * 100\n",
    "target_names = np.array([\"부정\", \"중립\", \"긍정\"])\n",
    "predicted_classes = target_names[np.argmax(probs, axis=1)]\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df = pd.DataFrame({\n",
    "    '리뷰내용': X,\n",
    "    '부정 확률 (%)': probs[:, 0] * 100,\n",
    "    '중립 확률 (%)': probs[:, 1] * 100,\n",
    "    '긍정 확률 (%)': probs[:, 2] * 100,\n",
    "    '예측된 클래스': predicted_classes\n",
    "})\n",
    "\n",
    "# CSV 파일로 저장\n",
    "results_df.to_csv('./data/review_predictions.csv', index=False)\n",
    "\n",
    "print(\"리뷰 분석 결과를 'review_predictions.csv'로 저장했습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c591104-b407-4c52-86b2-cbb8237e895a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰 분석 결과를 'review_predictions_with_product.csv'로 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 데이터 로드\n",
    "data = pd.read_csv('./data/review_before.csv')\n",
    "data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "data.columns = ['제품명', '닉네임', '나이', '피부타입', '성별', '평점', '리뷰내용']\n",
    "\n",
    "# 평점 기준\n",
    "def rating_replace(rating):\n",
    "    if rating in [5, 4]:  # 긍정은 2로 변경\n",
    "        return 2\n",
    "    elif rating == 3:  # 중립은 1로 변경\n",
    "        return 1\n",
    "    else:  # 부정은 0으로 변경\n",
    "        return 0\n",
    "\n",
    "data['감성분석 결과'] = data['평점'].apply(rating_replace)\n",
    "\n",
    "# 리뷰 내용 및 감성분석 결과\n",
    "X = data['리뷰내용']\n",
    "y = data['감성분석 결과']\n",
    "product_names = data['제품명']  # 제품명 컬럼 추가\n",
    "\n",
    "# 텍스트 감성 레이블 변환 함수\n",
    "def get_sentiment_label(value):\n",
    "    if value == 2:\n",
    "        return '긍정'\n",
    "    elif value == 1:\n",
    "        return '중립'\n",
    "    else:\n",
    "        return '부정'\n",
    "\n",
    "# 토큰화 함수 정의\n",
    "okt = Okt()\n",
    "\n",
    "def myTokenizer(text):\n",
    "    d = pd.DataFrame(okt.pos(text), columns=['morph', 'tag'])\n",
    "    d.set_index('tag', inplace=True)\n",
    "    if 'Verb' in d.index or 'Noun' in d.index or 'Adjective' in d.index:\n",
    "        return d.loc[d.index.intersection(['Verb', 'Noun', 'Adjective']), 'morph'].values\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf_pos = TfidfVectorizer(tokenizer=myTokenizer)\n",
    "tfidf_pos.fit(X)\n",
    "\n",
    "# 리뷰 내용 벡터화\n",
    "X_trains = tfidf_pos.transform(X)\n",
    "\n",
    "# 모델 로드 및 학습\n",
    "rf_model = RandomForestClassifier()  # 하이퍼파라미터 조정된 모델로 교체 필요\n",
    "rf_model.fit(X_trains, y)\n",
    "\n",
    "# 예측 수행\n",
    "probs = rf_model.predict_proba(X_trains)\n",
    "\n",
    "# 최대 확률 및 예측 클래스 계산\n",
    "max_probs = probs.max(axis=1) * 100\n",
    "target_names = np.array([\"부정\", \"중립\", \"긍정\"])\n",
    "predicted_classes = target_names[np.argmax(probs, axis=1)]\n",
    "\n",
    "# 실제 평점을 텍스트로 변환\n",
    "actual_sentiments = y.apply(get_sentiment_label)\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df = pd.DataFrame({\n",
    "    '제품명': product_names,\n",
    "    '리뷰내용': X,\n",
    "    '실제 평점': actual_sentiments,\n",
    "    '부정 확률 (%)': probs[:, 0] * 100,\n",
    "    '중립 확률 (%)': probs[:, 1] * 100,\n",
    "    '긍정 확률 (%)': probs[:, 2] * 100,\n",
    "    '예측된 클래스': predicted_classes\n",
    "})\n",
    "\n",
    "# CSV 파일로 저장\n",
    "results_df.to_csv('./data/review_predictions_with_product.csv', index=False)\n",
    "\n",
    "print(\"리뷰 분석 결과를 'review_predictions_with_product.csv'로 저장했습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b069a5b-6d7a-4edd-83f0-7cf6c49a3d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰 분석 결과를 'review_predictions_with_final_scores.csv'로 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 데이터 로드\n",
    "data = pd.read_csv('./data/review_before.csv')\n",
    "data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "data.columns = ['제품명', '닉네임', '나이', '피부타입', '성별', '평점', '리뷰내용']\n",
    "\n",
    "# 평점 기준\n",
    "def rating_replace(rating):\n",
    "    if rating in [5, 4]:  # 긍정은 2로 변경\n",
    "        return 2\n",
    "    elif rating == 3:  # 중립은 1로 변경\n",
    "        return 1\n",
    "    else:  # 부정은 0으로 변경\n",
    "        return 0\n",
    "\n",
    "data['감성분석 결과'] = data['평점'].apply(rating_replace)\n",
    "\n",
    "# 리뷰 내용 및 감성분석 결과\n",
    "X = data['리뷰내용']\n",
    "y = data['감성분석 결과']\n",
    "product_names = data['제품명']  # 제품명 컬럼 추가\n",
    "\n",
    "# 텍스트 감성 레이블 변환 함수\n",
    "def get_sentiment_label(value):\n",
    "    if value == 2:\n",
    "        return '긍정'\n",
    "    elif value == 1:\n",
    "        return '중립'\n",
    "    else:\n",
    "        return '부정'\n",
    "\n",
    "# 토큰화 함수 정의\n",
    "okt = Okt()\n",
    "\n",
    "def myTokenizer(text):\n",
    "    d = pd.DataFrame(okt.pos(text), columns=['morph', 'tag'])\n",
    "    d.set_index('tag', inplace=True)\n",
    "    if 'Verb' in d.index or 'Noun' in d.index or 'Adjective' in d.index:\n",
    "        return d.loc[d.index.intersection(['Verb', 'Noun', 'Adjective']), 'morph'].values\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf_pos = TfidfVectorizer(tokenizer=myTokenizer)\n",
    "tfidf_pos.fit(X)\n",
    "\n",
    "# 리뷰 내용 벡터화\n",
    "X_trains = tfidf_pos.transform(X)\n",
    "\n",
    "# 모델 로드 및 학습\n",
    "rf_model = RandomForestClassifier()  # 하이퍼파라미터 조정된 모델로 교체 필요\n",
    "rf_model.fit(X_trains, y)\n",
    "\n",
    "# 예측 수행\n",
    "probs = rf_model.predict_proba(X_trains)\n",
    "\n",
    "# 긍정, 부정, 중립 점수 계산\n",
    "positive_scores = 2 * probs[:, 2] - 1\n",
    "negative_scores = 1 - 2 * probs[:, 0]\n",
    "neutral_scores = np.zeros_like(probs[:, 1])  # 중립 점수는 0으로 설정\n",
    "\n",
    "# 최종 점수 계산 (긍정 점수와 부정 점수를 합산하고 중립 점수는 0으로)\n",
    "final_scores = positive_scores + negative_scores + neutral_scores\n",
    "\n",
    "# 실제 평점을 텍스트로 변환\n",
    "actual_sentiments = y.apply(get_sentiment_label)\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df = pd.DataFrame({\n",
    "    '제품명': product_names,\n",
    "    '리뷰내용': X,\n",
    "    '실제 평점': actual_sentiments,\n",
    "    '긍정 확률 (%)': probs[:, 2] * 100,\n",
    "    '부정 확률 (%)': probs[:, 0] * 100,\n",
    "    '중립 확률 (%)': probs[:, 1] * 100,\n",
    "    '점수': final_scores\n",
    "})\n",
    "\n",
    "# CSV 파일로 저장\n",
    "results_df.to_csv('./data/review_predictions_with_final_scores.csv', index=False)\n",
    "\n",
    "print(\"리뷰 분석 결과를 'review_predictions_with_final_scores.csv'로 저장했습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30a0bc0f-50e5-46fe-95e4-131492ae3f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰 분석 결과를 'review6700_predictions_with_final_scores.csv'로 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 데이터 로드\n",
    "data = pd.read_csv('./data/result_review.csv')\n",
    "# data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "data.columns = ['리뷰 번호', '제품명', '닉네임','나이','피부 타입','성별', '평점', '리뷰내용', '나이 그룹']\n",
    "\n",
    "# 평점 기준\n",
    "def rating_replace(rating):\n",
    "    if rating in [5, 4]:  # 긍정은 2로 변경\n",
    "        return 2\n",
    "    elif rating == 3:  # 중립은 1로 변경\n",
    "        return 1\n",
    "    else:  # 부정은 0으로 변경\n",
    "        return 0\n",
    "\n",
    "data['감성분석 결과'] = data['평점'].apply(rating_replace)\n",
    "\n",
    "# 리뷰 내용 및 감성분석 결과\n",
    "X = data['리뷰내용']\n",
    "y = data['감성분석 결과']\n",
    "product_names = data['제품명']  # 제품명 컬럼 추가\n",
    "\n",
    "# 텍스트 감성 레이블 변환 함수\n",
    "def get_sentiment_label(value):\n",
    "    if value == 2:\n",
    "        return '긍정'\n",
    "    elif value == 1:\n",
    "        return '중립'\n",
    "    else:\n",
    "        return '부정'\n",
    "\n",
    "# 토큰화 함수 정의\n",
    "okt = Okt()\n",
    "\n",
    "def myTokenizer(text):\n",
    "    d = pd.DataFrame(okt.pos(text), columns=['morph', 'tag'])\n",
    "    d.set_index('tag', inplace=True)\n",
    "    if 'Verb' in d.index or 'Noun' in d.index or 'Adjective' in d.index:\n",
    "        return d.loc[d.index.intersection(['Verb', 'Noun', 'Adjective']), 'morph'].values\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf_pos = TfidfVectorizer(tokenizer=myTokenizer)\n",
    "tfidf_pos.fit(X)\n",
    "\n",
    "# 리뷰 내용 벡터화\n",
    "X_trains = tfidf_pos.transform(X)\n",
    "\n",
    "# 모델 로드 및 학습\n",
    "rf_model = RandomForestClassifier()  # 하이퍼파라미터 조정된 모델로 교체 필요\n",
    "rf_model.fit(X_trains, y)\n",
    "\n",
    "# 예측 수행\n",
    "probs = rf_model.predict_proba(X_trains)\n",
    "\n",
    "# 긍정, 부정, 중립 점수 계산\n",
    "positive_scores = 2 * probs[:, 2] - 1\n",
    "negative_scores = 1 - 2 * probs[:, 0]\n",
    "neutral_scores = np.zeros_like(probs[:, 1])  # 중립 점수는 0으로 설정\n",
    "\n",
    "# 최종 점수 계산 (긍정 점수와 부정 점수를 합산하고 중립 점수는 0으로)\n",
    "final_scores = positive_scores + negative_scores + neutral_scores\n",
    "\n",
    "# 실제 평점을 텍스트로 변환\n",
    "actual_sentiments = y.apply(get_sentiment_label)\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df = pd.DataFrame({\n",
    "    '제품명': product_names,\n",
    "    '리뷰내용': X,\n",
    "    '실제 평점': actual_sentiments,\n",
    "    '긍정 확률 (%)': probs[:, 2] * 100,\n",
    "    '부정 확률 (%)': probs[:, 0] * 100,\n",
    "    '중립 확률 (%)': probs[:, 1] * 100,\n",
    "    '점수': final_scores\n",
    "})\n",
    "\n",
    "# CSV 파일로 저장\n",
    "results_df.to_csv('./data/review6700_predictions_with_final_scores.csv', index=False)\n",
    "\n",
    "print(\"리뷰 분석 결과를 'review6700_predictions_with_final_scores.csv'로 저장했습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3ae3cc-2caa-4a11-90e3-4988b38f73cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# 데이터 로드 및 컬럼 이름 설정\n",
    "data = pd.read_csv('./data/result_review_all_18.csv')\n",
    "data.columns = ['리뷰 번호', '제품명', '닉네임', '나이', '피부 타입', '성별', '평점', '리뷰내용', '나이 그룹']\n",
    "\n",
    "# 평점 기준 감성 분석 레이블 설정\n",
    "def rating_replace(rating):\n",
    "    if rating in [5, 4]:  # 긍정은 2로 변경\n",
    "        return 2\n",
    "    elif rating == 3:  # 중립은 1로 변경\n",
    "        return 1\n",
    "    else:  # 부정은 0으로 변경\n",
    "        return 0\n",
    "\n",
    "data['감성분석 결과'] = data['평점'].apply(rating_replace)\n",
    "\n",
    "# 리뷰 내용 및 감성분석 결과\n",
    "X = data['리뷰내용']\n",
    "y = data['감성분석 결과']\n",
    "\n",
    "# 토큰화 함수 정의\n",
    "okt = Okt()\n",
    "\n",
    "def myTokenizer(text):\n",
    "    d = pd.DataFrame(okt.pos(text), columns=['morph', 'tag'])\n",
    "    d.set_index('tag', inplace=True)\n",
    "    if ('Verb' in d.index) | ('Noun' in d.index) | ('Adjective' in d.index):\n",
    "        return d.loc[d.index.intersection(['Verb', 'Noun', 'Adjective']), 'morph'].values\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf_pos = TfidfVectorizer(tokenizer=myTokenizer)\n",
    "tfidf_pos.fit(X)\n",
    "X_trains = tfidf_pos.transform(X)\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trains, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 랜덤포레스트 모델 및 교차검증\n",
    "rf_model = RandomForestClassifier()\n",
    "grid_model = GridSearchCV(rf_model, param_grid={\n",
    "    'n_estimators': [500, 1000, 1500, 2000, 2500],\n",
    "    'max_depth': range(1, 6)\n",
    "}, n_jobs=-1, cv=5)\n",
    "grid_model.fit(X_train, y_train)\n",
    "\n",
    "# 최적 모델 추출 및 학습\n",
    "best_model = grid_model.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측 수행\n",
    "probs = best_model.predict_proba(X_trains)\n",
    "\n",
    "# 긍정, 부정, 중립 점수 계산\n",
    "positive_scores = 2 * probs[:, 2] - 1\n",
    "negative_scores = 1 - 2 * probs[:, 0]\n",
    "neutral_scores = np.zeros_like(probs[:, 1])  # 중립 점수는 0으로 설정\n",
    "\n",
    "# 최종 점수 계산\n",
    "final_scores = positive_scores + negative_scores + neutral_scores\n",
    "\n",
    "# 텍스트로 변환된 실제 평점\n",
    "def get_sentiment_label(value):\n",
    "    if value == 2:\n",
    "        return '긍정'\n",
    "    elif value == 1:\n",
    "        return '중립'\n",
    "    else:\n",
    "        return '부정'\n",
    "\n",
    "actual_sentiments = y.apply(get_sentiment_label)\n",
    "\n",
    "# 기존 데이터와 예측 결과 결합\n",
    "results_df = data.copy()  # 기존 데이터 복사\n",
    "results_df['실제 평점'] = actual_sentiments\n",
    "results_df['긍정 확률 (%)'] = probs[:, 2] * 100\n",
    "results_df['부정 확률 (%)'] = probs[:, 0] * 100\n",
    "results_df['중립 확률 (%)'] = probs[:, 1] * 100\n",
    "results_df['점수'] = final_scores\n",
    "\n",
    "# CSV 파일로 저장\n",
    "results_df.to_csv('./data/result_review_all_18_final_scores.csv', index=False)\n",
    "\n",
    "print(\"리뷰 분석 결과를 'result_review_all_18_final_scores.csv'로 저장했습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b5aa53a-fbe8-4462-8889-9601ff979bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰 분석 결과를 '0902_test.csv'로 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "data = pd.read_csv('./data/review_before.csv')\n",
    "data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "data.columns = ['제품명', '닉네임', '나이', '피부타입', '성별', '평점', '리뷰내용']\n",
    "\n",
    "# 평점 기준 감성 분석 레이블 설정\n",
    "def rating_replace(rating):\n",
    "    if rating in [5, 4]:  # 긍정은 2로 변경\n",
    "        return 2\n",
    "    elif rating == 3:  # 중립은 1로 변경\n",
    "        return 1\n",
    "    else:  # 부정은 0으로 변경\n",
    "        return 0\n",
    "\n",
    "data['감성분석 결과'] = data['평점'].apply(rating_replace)\n",
    "\n",
    "# 리뷰 내용 및 감성분석 결과\n",
    "X = data['리뷰내용']\n",
    "y = data['감성분석 결과']\n",
    "\n",
    "# 토큰화 함수 정의\n",
    "okt = Okt()\n",
    "\n",
    "def myTokenizer(text):\n",
    "    d = pd.DataFrame(okt.pos(text), columns=['morph', 'tag'])\n",
    "    d.set_index('tag', inplace=True)\n",
    "    if ('Verb' in d.index) | ('Noun' in d.index) | ('Adjective' in d.index):\n",
    "        return d.loc[d.index.intersection(['Verb', 'Noun', 'Adjective']), 'morph'].values\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf_pos = TfidfVectorizer(tokenizer=myTokenizer)\n",
    "tfidf_pos.fit(X)\n",
    "X_trains = tfidf_pos.transform(X)\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trains, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 랜덤포레스트 모델 및 교차검증\n",
    "rf_model = RandomForestClassifier()\n",
    "grid_model = GridSearchCV(rf_model, param_grid={\n",
    "    'n_estimators': [500, 1000, 1500, 2000, 2500],\n",
    "    'max_depth': range(1, 6)\n",
    "}, n_jobs=-1, cv=5)\n",
    "grid_model.fit(X_train, y_train)\n",
    "\n",
    "# 최적 모델 추출 및 학습\n",
    "best_model = grid_model.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측 수행\n",
    "probs = best_model.predict_proba(X_trains)\n",
    "\n",
    "# 긍정, 부정, 중립 점수 계산\n",
    "positive_scores = 2 * probs[:, 2] - 1\n",
    "negative_scores = 1 - 2 * probs[:, 0]\n",
    "neutral_scores = np.zeros_like(probs[:, 1])  # 중립 점수는 0으로 설정\n",
    "\n",
    "# 최종 점수 계산\n",
    "final_scores = positive_scores + negative_scores + neutral_scores\n",
    "\n",
    "# 텍스트로 변환된 실제 평점\n",
    "def get_sentiment_label(value):\n",
    "    if value == 2:\n",
    "        return '긍정'\n",
    "    elif value == 1:\n",
    "        return '중립'\n",
    "    else:\n",
    "        return '부정'\n",
    "\n",
    "actual_sentiments = y.apply(get_sentiment_label)\n",
    "\n",
    "# 기존 데이터와 예측 결과 결합\n",
    "results_df = data.copy()  # 기존 데이터 복사\n",
    "results_df['실제 평점'] = actual_sentiments\n",
    "results_df['긍정 확률 (%)'] = probs[:, 2] * 100\n",
    "results_df['부정 확률 (%)'] = probs[:, 0] * 100\n",
    "results_df['중립 확률 (%)'] = probs[:, 1] * 100\n",
    "results_df['점수'] = final_scores\n",
    "\n",
    "# CSV 파일로 저장\n",
    "results_df.to_csv('./data/0902_test.csv', index=False)\n",
    "\n",
    "print(\"리뷰 분석 결과를 '0902_test.csv'로 저장했습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416e72a7-17fd-4366-8254-99e8e5a3b472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6ce363-0ca9-4cc5-9a41-ae85bfb18ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33718d9-5b5b-4f99-9b70-9336e4c29e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
